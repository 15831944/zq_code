#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#第一行注释是为了告诉Linux/OS X系统，这是一个Python可执行程序，Windows系统会忽略这个注释；
#第二行注释是为了告诉Python解释器，按照UTF-8编码读取源代码，否则，你在源代码中写的中文输出可能会有乱码。

#初学python的时候，总是会被一系列编码问题搞的晕头转向，现在我就完完全全把这个编码问题搞清楚
#1.字符编码：
#    字符串也是一种数据类型，但是，字符串比较特殊的是还有一个编码问题
#    因为计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。
#    最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），所以，一个字节能表示的最大的整数就是255（二进制11111111=十进制255），
#    如果要表示更大的整数，就必须用更多的字节。比如两个字节可以表示的最大整数是65535，4个字节可以表示的最大整数是4294967295。
#    由于计算机是美国人发明的，因此，最早只有127个字母被编码到计算机里，也就是大小写英文字母、数字和一些符号，
#    这个编码表被称为ASCII编码，比如大写字母A的编码是65，小写字母z的编码是122
#    但是要处理中文显然一个字节是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，中国制定了GB2312编码，用来把中文编进去。
#    你可以想得到的是，全世界有上百种语言，日本把日文编到Shift_JIS里，韩国把韩文编到Euc-kr里，
#    各国有各国的标准，就会不可避免地出现冲突，结果就是，在多语言混合的文本中，显示出来会有乱码
#    因此，Unicode应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。
#    新的问题又出现了：如果统一成Unicode编码，乱码问题从此消失了。但是，如果你写的文本基本上全部是英文的话，
#    用Unicode编码比ASCII编码需要多一倍的存储空间，在存储和传输上就十分不划算。
#    所以，本着节约的精神，又出现了把Unicode编码转化为“可变长编码”的UTF-8编码。
#    UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，
#    只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间
#    举个例子：用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件

#2.Python的字符串
#    搞清楚了令人头疼的字符编码问题后，我们再来研究Python的字符串
a = ord('A')    #获取字符的整数表示
print(a)		#65
b = ord('中')    #获取字符的整数表示
print(b)		 #20013
c = chr(66)     #把编码转换为对应的字符
print(c)		#'B',
d = chr(25991)  #把编码转换为对应的字符
print(d)		#'文'

#如果知道字符的整数编码，还可以用十六进制这么写str
e = '\u4e2d\u6587'  
print(e)			#‘中文’

#其中，bytes和str相互转换
f = 'ABC'.encode('ascii')   
print(f)			#b'ABC'
g =  '中文'.encode('utf-8')    
print(g)			#b'\xe4\xb8\xad\xe6\x96\x87
h = b'ABC'.decode('ascii')  
print(h)			 #'ABC'
i = b'\xe4\xb8\xad\xe6\x96\x87'.decode('utf-8')
print(i)			 #'中文'